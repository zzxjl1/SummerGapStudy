{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mnist分类任务：\n",
    "\n",
    "- 网络基本构建与训练方法，常用函数解析\n",
    "\n",
    "- torch.nn.functional模块\n",
    "\n",
    "- nn.Module模块\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取Mnist数据集\n",
    "- 会自动进行下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "784是mnist数据集每个样本的像素点个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "pyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
    "print(x_train.shape)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意数据需转换成tensor才能参与后续建模训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "torch.Size([50000, 784])\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")\n",
    "n, c = x_train.shape\n",
    "x_train, x_train.shape, y_train.min(), y_train.max()\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nn.functional 很多层和函数在这里都会见到\n",
    "\n",
    "torch.nn.functional中有很多功能，后续会常用的。那什么时候使用nn.Module，什么时候使用nn.functional呢？一般情况下，如果模型有可学习的参数，最好用nn.Module，其他情况nn.functional相对更简单一些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(xb):\n",
    "    return xb.mm(weights) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14.8359, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "bs = 64\n",
    "xb = x_train[0:bs]  # a mini-batch from x\n",
    "yb = y_train[0:bs]\n",
    "weights = torch.randn([784, 10], dtype = torch.float,  requires_grad = True) \n",
    "bs = 64\n",
    "bias = torch.zeros(10, requires_grad=True)\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建一个model来更简化代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 必须继承nn.Module且在其构造函数中需调用nn.Module的构造函数\n",
    "- 无需写反向传播函数，nn.Module能够利用autograd自动实现反向传播\n",
    "- Module中的可学习参数可以通过named_parameters()或者parameters()返回迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Mnist_NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(784, 128)\n",
    "        self.hidden2 = nn.Linear(128, 256)\n",
    "        self.out  = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist_NN(\n",
      "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (hidden2): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (out): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Mnist_NN()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以打印我们定义好名字里的权重和偏置项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden1.weight Parameter containing:\n",
      "tensor([[ 3.3924e-02,  2.8203e-02,  7.4763e-03,  ...,  1.2120e-02,\n",
      "         -3.1068e-02, -2.6079e-02],\n",
      "        [-1.9429e-02,  3.4990e-02, -1.2515e-02,  ...,  1.0827e-02,\n",
      "         -1.9339e-02,  1.7851e-02],\n",
      "        [ 1.7933e-03, -1.6740e-02, -8.8343e-03,  ..., -7.9636e-05,\n",
      "          1.8105e-02,  1.4471e-02],\n",
      "        ...,\n",
      "        [ 2.4911e-02, -2.3699e-02,  3.3719e-02,  ..., -3.4438e-02,\n",
      "         -1.0813e-02,  3.4444e-02],\n",
      "        [ 3.1036e-02, -1.6719e-02,  1.2127e-02,  ...,  9.0826e-03,\n",
      "         -1.2473e-02, -1.2882e-02],\n",
      "        [ 3.2334e-02, -1.0435e-02, -6.0367e-03,  ...,  2.9114e-02,\n",
      "         -3.1620e-02, -2.8967e-04]], requires_grad=True) torch.Size([128, 784])\n",
      "hidden1.bias Parameter containing:\n",
      "tensor([ 0.0105, -0.0028,  0.0022,  0.0102, -0.0204, -0.0241,  0.0161,  0.0071,\n",
      "         0.0260,  0.0242,  0.0216, -0.0096, -0.0130, -0.0237, -0.0160,  0.0052,\n",
      "        -0.0199,  0.0168,  0.0141,  0.0224, -0.0355,  0.0306,  0.0176,  0.0253,\n",
      "        -0.0204,  0.0119,  0.0187, -0.0127,  0.0232,  0.0282,  0.0010,  0.0256,\n",
      "        -0.0035, -0.0187, -0.0007, -0.0242, -0.0239,  0.0337,  0.0224,  0.0146,\n",
      "         0.0252,  0.0151,  0.0085,  0.0315, -0.0163, -0.0300, -0.0193, -0.0225,\n",
      "         0.0332,  0.0231, -0.0051, -0.0112, -0.0109,  0.0149,  0.0097, -0.0299,\n",
      "        -0.0072,  0.0231,  0.0024, -0.0106, -0.0064,  0.0306,  0.0352,  0.0254,\n",
      "        -0.0061,  0.0215,  0.0279,  0.0313,  0.0078, -0.0204,  0.0201, -0.0009,\n",
      "        -0.0325,  0.0326,  0.0188, -0.0094,  0.0081,  0.0109, -0.0282, -0.0006,\n",
      "         0.0113,  0.0179,  0.0136, -0.0268,  0.0333, -0.0189, -0.0142,  0.0018,\n",
      "         0.0207,  0.0078, -0.0062,  0.0023, -0.0327, -0.0026,  0.0265,  0.0085,\n",
      "         0.0225,  0.0067,  0.0283, -0.0345,  0.0191,  0.0150, -0.0057,  0.0242,\n",
      "        -0.0024, -0.0225,  0.0212, -0.0237,  0.0261, -0.0262, -0.0082,  0.0030,\n",
      "         0.0121,  0.0288, -0.0223, -0.0281,  0.0339, -0.0010,  0.0276, -0.0032,\n",
      "        -0.0057,  0.0091,  0.0148, -0.0233,  0.0329,  0.0147, -0.0030, -0.0110],\n",
      "       requires_grad=True) torch.Size([128])\n",
      "hidden2.weight Parameter containing:\n",
      "tensor([[ 0.0484, -0.0711,  0.0741,  ..., -0.0681,  0.0217,  0.0579],\n",
      "        [ 0.0464,  0.0417,  0.0403,  ...,  0.0119,  0.0363,  0.0654],\n",
      "        [-0.0482,  0.0796,  0.0830,  ..., -0.0867, -0.0395,  0.0247],\n",
      "        ...,\n",
      "        [ 0.0788,  0.0096, -0.0373,  ...,  0.0827,  0.0569,  0.0405],\n",
      "        [-0.0295, -0.0624,  0.0096,  ..., -0.0454, -0.0673,  0.0094],\n",
      "        [ 0.0565,  0.0626, -0.0499,  ..., -0.0635,  0.0693, -0.0530]],\n",
      "       requires_grad=True) torch.Size([256, 128])\n",
      "hidden2.bias Parameter containing:\n",
      "tensor([ 4.1214e-02, -3.0942e-02,  7.9026e-02, -6.1003e-02,  7.1821e-03,\n",
      "        -5.5779e-02,  7.5216e-02,  5.6451e-02, -5.7143e-02, -1.1428e-02,\n",
      "        -4.3818e-02, -6.5685e-03,  6.3144e-02,  1.2554e-02, -8.1287e-02,\n",
      "        -4.9692e-02,  2.7073e-02,  5.4017e-02, -6.6274e-02, -8.5171e-02,\n",
      "         6.7953e-02, -7.3242e-02, -5.2110e-02, -7.9230e-02, -8.4390e-02,\n",
      "         5.5945e-03, -7.2341e-02,  6.6641e-02, -8.0669e-02,  3.8227e-02,\n",
      "         9.2082e-03,  8.5970e-02, -8.2100e-02,  4.0674e-02,  7.9773e-02,\n",
      "         1.0653e-02, -8.0842e-02,  6.0420e-03, -3.9711e-02, -2.4727e-02,\n",
      "        -3.5701e-02,  4.0757e-02, -2.2345e-02, -2.7343e-02, -3.3003e-02,\n",
      "        -8.5779e-02, -1.1295e-02, -4.1443e-03, -6.9217e-03,  1.9270e-02,\n",
      "        -7.1973e-02, -2.6330e-02,  8.1763e-02,  6.0496e-02,  4.7536e-02,\n",
      "         1.0000e-02,  6.8829e-02,  3.0841e-02, -5.4171e-03, -1.9585e-02,\n",
      "        -4.4928e-02, -3.3062e-03,  2.5153e-02,  1.3852e-02,  1.7841e-02,\n",
      "        -8.0512e-02,  7.8608e-02,  6.2876e-02,  3.7246e-02,  5.3048e-02,\n",
      "         8.6025e-02,  8.6839e-02,  6.0930e-02, -7.0225e-02,  6.7229e-02,\n",
      "        -5.4407e-02, -3.1762e-02, -5.6206e-02, -2.7369e-02,  1.3461e-03,\n",
      "        -2.5780e-02, -6.3348e-02,  7.7150e-02,  7.4060e-02, -9.0325e-03,\n",
      "         3.1047e-02, -3.7500e-02, -6.6309e-02, -5.7216e-02, -3.7858e-02,\n",
      "         2.2882e-02, -6.0725e-03,  8.1120e-02,  1.8622e-02, -5.1253e-02,\n",
      "         7.4502e-02, -7.3112e-02, -1.4933e-02,  4.3766e-03,  7.0111e-02,\n",
      "         3.7717e-02, -4.8013e-02, -5.2493e-02, -6.9938e-02, -1.9023e-02,\n",
      "        -7.4446e-03,  5.8529e-03, -3.2153e-03, -2.8196e-02,  7.6044e-03,\n",
      "         1.2079e-02, -2.1255e-02, -8.4020e-02,  5.2530e-02, -2.2297e-02,\n",
      "        -1.7302e-02, -1.5252e-02, -3.8586e-02, -5.7642e-02, -9.4594e-03,\n",
      "        -4.1621e-02, -8.6370e-02, -1.4214e-02, -3.4822e-02, -2.0701e-02,\n",
      "        -8.6665e-02, -6.9253e-02, -5.3055e-02, -4.7901e-02, -1.5161e-02,\n",
      "        -2.8044e-02, -8.3698e-02, -2.5532e-02, -5.6552e-02,  5.4601e-02,\n",
      "         1.0756e-02, -3.7712e-02, -7.7376e-02,  8.8457e-03, -5.4170e-02,\n",
      "        -3.4004e-03, -6.2737e-02,  5.5803e-02, -6.8294e-02, -8.7456e-03,\n",
      "        -6.3020e-03, -5.3308e-02, -1.2744e-02,  4.2939e-02, -3.1540e-02,\n",
      "        -3.8625e-02,  2.0812e-02, -7.9946e-02, -3.9802e-02,  2.2376e-02,\n",
      "        -6.1738e-02, -6.5839e-02, -4.0225e-02,  4.7057e-02,  6.8774e-02,\n",
      "         7.0451e-02, -8.5481e-03, -6.3668e-02,  2.3268e-02, -7.9030e-02,\n",
      "         1.7566e-02,  3.7846e-03,  1.8937e-02, -5.7279e-02, -7.8164e-02,\n",
      "         1.3125e-02,  2.9360e-02,  6.9127e-02, -2.0849e-02,  7.7672e-03,\n",
      "        -5.3696e-02,  3.0163e-02,  8.8002e-02,  5.6060e-02, -1.6142e-02,\n",
      "        -5.6938e-02,  5.5696e-02, -7.8496e-02,  4.9316e-02,  1.3891e-02,\n",
      "         6.0498e-02, -5.2059e-02,  5.9565e-02,  6.9002e-02, -1.0031e-02,\n",
      "         6.8914e-02,  6.9442e-02,  8.2122e-02, -2.8492e-02, -8.4624e-02,\n",
      "        -5.7944e-02,  2.1855e-02, -7.7756e-02, -3.7511e-03, -8.2634e-02,\n",
      "         6.7072e-02, -3.6126e-02,  1.4954e-02, -6.1962e-02, -3.2417e-02,\n",
      "         3.2602e-02, -6.1959e-02, -6.5338e-02,  5.4267e-02,  6.2060e-02,\n",
      "         4.2661e-03,  7.4613e-02,  7.3497e-02, -8.4596e-02,  6.8940e-02,\n",
      "         4.9981e-02, -1.6778e-02,  2.4430e-02, -6.9516e-02,  7.2725e-05,\n",
      "        -5.2120e-02, -1.2162e-02, -2.9474e-02,  8.9577e-03, -6.4075e-02,\n",
      "         6.6706e-02,  7.9142e-02, -8.7458e-02, -1.5273e-02, -5.7785e-02,\n",
      "        -2.6258e-03, -6.4484e-02, -1.8351e-02,  5.3794e-02,  9.5525e-03,\n",
      "        -7.6993e-03, -2.9276e-02,  3.5239e-02,  8.1484e-02, -6.7428e-02,\n",
      "        -2.1429e-02, -9.6601e-03,  4.4437e-02, -6.8685e-02,  5.8726e-02,\n",
      "         9.5654e-03,  6.3062e-02, -8.1201e-02,  7.1670e-02, -5.6789e-02,\n",
      "        -6.2296e-02, -6.2712e-02,  7.6201e-02,  3.4508e-02,  1.0520e-02,\n",
      "         8.2998e-02], requires_grad=True) torch.Size([256])\n",
      "out.weight Parameter containing:\n",
      "tensor([[ 0.0034,  0.0532,  0.0163,  ...,  0.0373,  0.0500,  0.0310],\n",
      "        [-0.0246,  0.0151, -0.0186,  ..., -0.0484, -0.0182,  0.0101],\n",
      "        [ 0.0316, -0.0471, -0.0099,  ...,  0.0409, -0.0061,  0.0422],\n",
      "        ...,\n",
      "        [-0.0511,  0.0189,  0.0462,  ..., -0.0173, -0.0344,  0.0471],\n",
      "        [ 0.0290, -0.0277,  0.0076,  ...,  0.0151, -0.0428,  0.0306],\n",
      "        [ 0.0262,  0.0469,  0.0543,  ...,  0.0152, -0.0171, -0.0567]],\n",
      "       requires_grad=True) torch.Size([10, 256])\n",
      "out.bias Parameter containing:\n",
      "tensor([ 0.0170, -0.0432, -0.0568, -0.0274, -0.0505,  0.0447, -0.0214,  0.0480,\n",
      "        -0.0048, -0.0575], requires_grad=True) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in net.named_parameters():\n",
    "    print(name, parameter,parameter.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用TensorDataset和DataLoader来简化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 一般在训练模型时加上model.train()，这样会正常使用Batch Normalization和 Dropout\n",
    "- 测试的时候一般选择model.eval()，这样就不会使用Batch Normalization和 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit(steps, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for step in range(steps):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        print('当前step:'+str(step), '验证集损失：'+str(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "def get_model():\n",
    "    model = Mnist_NN()\n",
    "    return model, optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三行搞定！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前step:0 验证集损失：2.280521762084961\n",
      "当前step:1 验证集损失：2.2493453804016115\n",
      "当前step:2 验证集损失：2.199923737716675\n",
      "当前step:3 验证集损失：2.11922739982605\n",
      "当前step:4 验证集损失：1.9896063777923585\n",
      "当前step:5 验证集损失：1.7941044673919677\n",
      "当前step:6 验证集损失：1.5410480503082276\n",
      "当前step:7 验证集损失：1.2829019281387328\n",
      "当前step:8 验证集损失：1.0695147428512572\n",
      "当前step:9 验证集损失：0.9111745872497559\n",
      "当前step:10 验证集损失：0.7951208155632019\n",
      "当前step:11 验证集损失：0.708297229385376\n",
      "当前step:12 验证集损失：0.6416949621200562\n",
      "当前step:13 验证集损失：0.5893908842086792\n",
      "当前step:14 验证集损失：0.547949939584732\n",
      "当前step:15 验证集损失：0.5144602170467377\n",
      "当前step:16 验证集损失：0.4868099680900574\n",
      "当前step:17 验证集损失：0.4642222202301025\n",
      "当前step:18 验证集损失：0.445196675491333\n",
      "当前step:19 验证集损失：0.42932558765411377\n",
      "当前step:20 验证集损失：0.4155343008995056\n",
      "当前step:21 验证集损失：0.4032670767068863\n",
      "当前step:22 验证集损失：0.39361734399795534\n",
      "当前step:23 验证集损失：0.3847621057033539\n",
      "当前step:24 验证集损失：0.3760298326253891\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(25, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.6018794  -6.568608    2.013435   -1.7659931   1.2831159   1.218706\n",
      "  5.6075215  -2.8065872  -1.0922228  -0.43885943]\n",
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 2\n",
    "pyplot.imshow(x_valid[index].reshape((28, 28)), cmap=\"gray\")\n",
    "print(model(x_valid[index]).detach().numpy())\n",
    "print(y_valid[index].numpy())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3cc5292bf5c830798e60369264793d4ad446af4d95064df5045c9e5f7d07eceb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
