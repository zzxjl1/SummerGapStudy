{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mnist分类任务：\n",
    "\n",
    "- 网络基本构建与训练方法，常用函数解析\n",
    "\n",
    "- torch.nn.functional模块\n",
    "\n",
    "- nn.Module模块\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取Mnist数据集\n",
    "- 会自动进行下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "784是mnist数据集每个样本的像素点个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "pyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
    "print(x_train.shape)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意数据需转换成tensor才能参与后续建模训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "torch.Size([50000, 784])\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")\n",
    "n, c = x_train.shape\n",
    "x_train, x_train.shape, y_train.min(), y_train.max()\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nn.functional 很多层和函数在这里都会见到\n",
    "\n",
    "torch.nn.functional中有很多功能，后续会常用的。那什么时候使用nn.Module，什么时候使用nn.functional呢？一般情况下，如果模型有可学习的参数，最好用nn.Module，其他情况nn.functional相对更简单一些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(xb):\n",
    "    return xb.mm(weights) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.4170, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "bs = 64\n",
    "xb = x_train[0:bs]  # a mini-batch from x\n",
    "yb = y_train[0:bs]\n",
    "weights = torch.randn([784, 10], dtype = torch.float,  requires_grad = True) \n",
    "bs = 64\n",
    "bias = torch.zeros(10, requires_grad=True)\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建一个model来更简化代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 必须继承nn.Module且在其构造函数中需调用nn.Module的构造函数\n",
    "- 无需写反向传播函数，nn.Module能够利用autograd自动实现反向传播\n",
    "- Module中的可学习参数可以通过named_parameters()或者parameters()返回迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Mnist_NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(784, 128)\n",
    "        self.hidden2 = nn.Linear(128, 256)\n",
    "        self.out  = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist_NN(\n",
      "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (hidden2): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (out): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Mnist_NN()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以打印我们定义好名字里的权重和偏置项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden1.weight Parameter containing:\n",
      "tensor([[ 1.9725e-03,  2.4007e-02,  1.7163e-02,  ..., -9.3078e-03,\n",
      "         -1.8658e-02, -8.0369e-05],\n",
      "        [-2.7364e-04, -2.5378e-02,  3.1618e-02,  ..., -2.5431e-02,\n",
      "         -1.1120e-02, -1.0370e-02],\n",
      "        [ 4.6401e-03, -1.7845e-02,  4.8508e-04,  ..., -2.3005e-02,\n",
      "         -7.5768e-03, -2.3145e-02],\n",
      "        ...,\n",
      "        [-2.6735e-02, -1.3820e-02,  1.0017e-03,  ..., -2.1038e-02,\n",
      "          1.6410e-02,  3.4632e-02],\n",
      "        [-2.4089e-02, -2.8203e-02, -1.0975e-02,  ...,  2.9672e-03,\n",
      "         -2.5152e-02,  1.7972e-02],\n",
      "        [-2.0497e-02, -2.9084e-02, -2.6879e-02,  ...,  2.6285e-02,\n",
      "          8.0779e-03,  2.2353e-02]], requires_grad=True) torch.Size([128, 784])\n",
      "hidden1.bias Parameter containing:\n",
      "tensor([-0.0045, -0.0159,  0.0323, -0.0048, -0.0151, -0.0043,  0.0231,  0.0238,\n",
      "         0.0306, -0.0299,  0.0309,  0.0356, -0.0074,  0.0153,  0.0265, -0.0326,\n",
      "        -0.0306, -0.0096,  0.0031, -0.0108,  0.0267, -0.0016, -0.0263, -0.0125,\n",
      "         0.0090,  0.0034, -0.0003, -0.0071,  0.0076, -0.0223, -0.0237, -0.0252,\n",
      "        -0.0223, -0.0059, -0.0117,  0.0253,  0.0315,  0.0316,  0.0037, -0.0017,\n",
      "         0.0298, -0.0100,  0.0275, -0.0245, -0.0059, -0.0004,  0.0326, -0.0020,\n",
      "        -0.0027,  0.0276,  0.0209,  0.0274,  0.0026,  0.0324,  0.0143, -0.0137,\n",
      "        -0.0339, -0.0116,  0.0005,  0.0344,  0.0023, -0.0278,  0.0314, -0.0031,\n",
      "        -0.0325,  0.0110,  0.0199, -0.0064, -0.0276,  0.0153,  0.0026,  0.0355,\n",
      "        -0.0083,  0.0094, -0.0119,  0.0206, -0.0212,  0.0034, -0.0327, -0.0148,\n",
      "        -0.0056, -0.0089,  0.0193, -0.0095,  0.0007, -0.0303,  0.0108,  0.0347,\n",
      "         0.0304, -0.0169, -0.0313, -0.0323, -0.0310,  0.0227, -0.0138,  0.0315,\n",
      "        -0.0301,  0.0102, -0.0271, -0.0031,  0.0063,  0.0329,  0.0273,  0.0108,\n",
      "        -0.0133,  0.0219, -0.0046, -0.0340, -0.0327,  0.0344,  0.0209,  0.0060,\n",
      "         0.0238, -0.0288, -0.0012, -0.0014,  0.0167, -0.0173,  0.0313, -0.0298,\n",
      "         0.0197,  0.0176, -0.0135,  0.0110, -0.0096, -0.0097, -0.0194,  0.0349],\n",
      "       requires_grad=True) torch.Size([128])\n",
      "hidden2.weight Parameter containing:\n",
      "tensor([[-0.0871, -0.0618,  0.0337,  ...,  0.0576, -0.0138,  0.0788],\n",
      "        [-0.0026,  0.0546,  0.0848,  ...,  0.0178, -0.0385, -0.0228],\n",
      "        [ 0.0341, -0.0868,  0.0014,  ...,  0.0822,  0.0712, -0.0115],\n",
      "        ...,\n",
      "        [ 0.0096,  0.0524, -0.0112,  ...,  0.0042,  0.0655,  0.0711],\n",
      "        [ 0.0587,  0.0316,  0.0164,  ..., -0.0571,  0.0213,  0.0575],\n",
      "        [ 0.0442,  0.0388,  0.0872,  ..., -0.0631, -0.0481,  0.0196]],\n",
      "       requires_grad=True) torch.Size([256, 128])\n",
      "hidden2.bias Parameter containing:\n",
      "tensor([-5.3837e-02,  2.1378e-02, -4.6012e-02, -2.6209e-02, -3.8083e-02,\n",
      "         1.0891e-02, -2.9093e-02, -6.0558e-03, -8.1531e-02,  3.6981e-02,\n",
      "         4.9545e-02, -4.6140e-02, -2.8816e-02,  3.4700e-02,  3.4051e-02,\n",
      "        -6.8382e-02,  8.7355e-02, -4.8825e-02,  5.7149e-02, -9.9958e-04,\n",
      "        -1.8745e-02, -4.9099e-02, -5.0443e-02,  2.1579e-02, -7.6222e-02,\n",
      "         7.9622e-02, -7.1234e-02,  9.1989e-03,  6.2137e-03, -7.6525e-02,\n",
      "         7.8179e-02,  1.8972e-02, -5.2189e-02, -4.0966e-02, -5.2874e-02,\n",
      "        -7.9085e-02, -3.3766e-02, -8.7633e-02,  5.9926e-02,  1.3581e-02,\n",
      "        -1.4539e-02, -5.9297e-02, -3.5088e-02,  7.9978e-02,  6.7338e-02,\n",
      "        -8.9161e-03,  5.6099e-02,  2.8738e-02, -4.5736e-02,  3.9304e-03,\n",
      "        -4.9429e-02,  6.3108e-02,  8.6050e-03, -6.6526e-02,  2.0015e-02,\n",
      "         6.0872e-02,  7.7185e-02,  4.7837e-02,  7.1013e-02, -2.4903e-03,\n",
      "         3.7111e-02, -7.8537e-02,  1.2439e-02,  8.4961e-02, -4.1360e-02,\n",
      "         7.8923e-02, -8.3717e-02, -3.4352e-03,  5.6879e-02, -6.1416e-02,\n",
      "         5.1481e-03,  7.5650e-02, -4.9053e-03,  7.2527e-02,  2.0320e-02,\n",
      "        -8.1625e-02, -1.7989e-02, -8.7152e-02, -5.5576e-02,  1.2394e-02,\n",
      "         4.9646e-02, -2.3026e-02,  4.0651e-02,  7.3442e-02,  6.7632e-02,\n",
      "        -3.4412e-02, -5.0115e-02,  1.5295e-02,  1.8372e-02,  4.7226e-02,\n",
      "        -8.4794e-02, -5.8392e-02,  3.2152e-02,  6.5484e-02,  4.0011e-02,\n",
      "         2.3448e-02, -2.6264e-02,  6.0222e-03, -7.3277e-02, -6.6655e-03,\n",
      "         7.1356e-02,  7.0716e-03,  1.5835e-02,  1.4710e-02, -4.2973e-02,\n",
      "        -7.7053e-03,  1.9728e-02,  5.0755e-02,  6.7866e-02, -5.2863e-02,\n",
      "         5.7076e-02, -3.1304e-03,  4.9798e-02,  6.5337e-02,  7.2198e-02,\n",
      "        -7.9944e-02, -7.9055e-02, -5.7685e-02, -3.4254e-02,  5.3198e-02,\n",
      "        -6.9473e-02,  8.3487e-02,  3.3697e-02, -7.7655e-02,  4.9762e-02,\n",
      "        -3.1571e-02,  3.3540e-02, -8.4584e-02, -5.0743e-02,  4.6524e-02,\n",
      "        -7.1000e-02,  2.0182e-02, -5.0518e-02, -6.0802e-02,  4.1368e-02,\n",
      "        -1.7357e-02,  7.3147e-02,  3.3905e-03, -4.5808e-03,  7.5043e-02,\n",
      "        -5.5564e-02,  2.4845e-02, -4.6927e-02, -4.0130e-02, -5.1205e-02,\n",
      "         5.6133e-02, -3.7274e-02,  1.1092e-02, -5.9606e-02,  7.8325e-03,\n",
      "         2.7381e-02, -4.7259e-02,  1.5555e-02,  7.8726e-02,  2.1190e-02,\n",
      "        -4.0163e-02,  1.2054e-02, -5.1498e-02,  3.0449e-02,  6.7377e-02,\n",
      "         8.2377e-02,  8.9032e-03,  7.0633e-02, -4.8182e-02,  3.2846e-02,\n",
      "         6.6935e-03,  7.3976e-02,  4.5342e-02, -6.5021e-02, -6.7743e-02,\n",
      "        -8.2805e-02,  7.1692e-02,  2.1317e-02,  3.0935e-02, -6.6828e-02,\n",
      "        -6.4854e-02, -4.9873e-02,  3.1904e-02, -8.0027e-02,  5.9887e-02,\n",
      "         5.5740e-02,  3.1477e-02, -3.3664e-02, -4.7360e-02, -6.4185e-02,\n",
      "         8.5565e-03,  1.1517e-03, -1.8485e-02,  8.3993e-03, -5.9732e-02,\n",
      "         3.8267e-02,  1.5214e-02, -8.7217e-02,  3.2658e-02,  8.0152e-02,\n",
      "         7.3975e-02, -4.4422e-02, -1.2344e-02,  3.7418e-02, -4.6713e-02,\n",
      "         4.5918e-03,  3.9638e-02, -6.8350e-02,  5.8560e-02, -5.8958e-02,\n",
      "         3.5890e-02, -8.1318e-02,  4.6302e-02, -1.8133e-02, -3.7755e-02,\n",
      "         9.0633e-04,  6.6683e-03,  3.6760e-02,  4.6127e-02, -8.6180e-02,\n",
      "         2.2198e-02, -4.6248e-02, -5.6712e-02, -5.2760e-02,  5.3688e-02,\n",
      "         5.0306e-02,  1.2577e-02, -7.4513e-02,  2.9978e-02, -8.7697e-02,\n",
      "        -4.6312e-02,  5.8401e-02,  3.1125e-02,  4.7308e-02, -4.4681e-02,\n",
      "        -7.0427e-02,  1.3039e-02,  2.8018e-02,  8.6628e-02,  4.1600e-02,\n",
      "        -2.5432e-02,  5.1567e-02, -5.4581e-02, -2.6076e-04, -9.8698e-05,\n",
      "         4.0625e-02, -1.7344e-02,  8.4014e-03,  3.0758e-02, -3.4777e-03,\n",
      "        -1.1964e-02, -1.8320e-02,  3.9256e-04,  5.5810e-02, -8.3119e-02,\n",
      "        -1.1430e-02, -5.6027e-02, -7.6367e-02,  1.6650e-02,  4.8224e-02,\n",
      "        -3.7142e-02], requires_grad=True) torch.Size([256])\n",
      "out.weight Parameter containing:\n",
      "tensor([[-0.0117, -0.0050,  0.0316,  ...,  0.0422,  0.0148,  0.0241],\n",
      "        [-0.0579, -0.0376, -0.0233,  ..., -0.0467,  0.0546,  0.0135],\n",
      "        [ 0.0118,  0.0363, -0.0412,  ...,  0.0156, -0.0108,  0.0294],\n",
      "        ...,\n",
      "        [-0.0465,  0.0547, -0.0397,  ..., -0.0136, -0.0099,  0.0120],\n",
      "        [-0.0480,  0.0532,  0.0064,  ...,  0.0527,  0.0074, -0.0400],\n",
      "        [ 0.0142,  0.0591,  0.0178,  ..., -0.0441,  0.0448,  0.0004]],\n",
      "       requires_grad=True) torch.Size([10, 256])\n",
      "out.bias Parameter containing:\n",
      "tensor([-0.0071, -0.0117, -0.0501, -0.0128,  0.0489, -0.0372,  0.0196, -0.0377,\n",
      "         0.0295,  0.0440], requires_grad=True) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in net.named_parameters():\n",
    "    print(name, parameter,parameter.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用TensorDataset和DataLoader来简化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 一般在训练模型时加上model.train()，这样会正常使用Batch Normalization和 Dropout\n",
    "- 测试的时候一般选择model.eval()，这样就不会使用Batch Normalization和 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit(steps, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for step in range(steps):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        print('当前step:'+str(step), '验证集损失：'+str(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "def get_model():\n",
    "    model = Mnist_NN()\n",
    "    return model, optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三行搞定！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前step:0 验证集损失：2.2779212478637696\n",
      "当前step:1 验证集损失：2.2431859161376955\n",
      "当前step:2 验证集损失：2.1895699562072752\n",
      "当前step:3 验证集损失：2.100343092346191\n",
      "当前step:4 验证集损失：1.9567430870056153\n",
      "当前step:5 验证集损失：1.7462687885284425\n",
      "当前step:6 验证集损失：1.4831572675704956\n",
      "当前step:7 验证集损失：1.2227021856307982\n",
      "当前step:8 验证集损失：1.015511714553833\n",
      "当前step:9 验证集损失：0.8659543516159057\n",
      "当前step:10 验证集损失：0.7588233054161072\n",
      "当前step:11 验证集损失：0.6805933215141297\n",
      "当前step:12 验证集损失：0.6218414553642273\n",
      "当前step:13 验证集损失：0.5773146168708801\n",
      "当前step:14 验证集损失：0.54110722489357\n",
      "当前step:15 验证集损失：0.5123381072044373\n",
      "当前step:16 验证集损失：0.48865195045471194\n",
      "当前step:17 验证集损失：0.46917831168174745\n",
      "当前step:18 验证集损失：0.45184624152183533\n",
      "当前step:19 验证集损失：0.4371643262863159\n",
      "当前step:20 验证集损失：0.4240464762687683\n",
      "当前step:21 验证集损失：0.4130564507961273\n",
      "当前step:22 验证集损失：0.4032058767080307\n",
      "当前step:23 验证集损失：0.3939127561330795\n",
      "当前step:24 验证集损失：0.38586334459781646\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(25, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3cc5292bf5c830798e60369264793d4ad446af4d95064df5045c9e5f7d07eceb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
